---
custom_edit_url: https://github.com/ag2ai/ag2/edit/main/notebook/agents_websurfer.ipynb
description: WebSurfer Agent
source_notebook: /notebook/agents_websurfer.ipynb
tags:
- agents
- browser-use
- crawl4ai
- webscraping
- function calling
title: WebSurferAgent
---

<a href="https://colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/agents_websurfer.ipynb" class="colab-badge" target="_blank"><img noZoom src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a>
<a href="https://github.com/ag2ai/ag2/blob/main/notebook/agents_websurfer.ipynb" class="github-badge" target="_blank"><img noZoom src="https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github" alt="Open on GitHub" /></a>




In
[`browser-use tool`](https://github.com/ag2ai/ag2/blob/main/notebook/tools_browser_use.ipynb)
and
[`crawl4ai tool`](https://github.com/ag2ai/ag2/blob/main/notebook/tools_crawl4ai.ipynb)
notebooks, we demonstrated how to create Agents with basic web surfing
capabilities.

Now, we’re taking it a step further with `WebSurferAgent`—a powerful
agent equipped with built-in web surfing tools right out of the box!

## WebSurferAgent with `browser-use` tool

**Warning:** [`Browser Use`](https://github.com/browser-use/browser-use)
requires **Python 3.11 or higher**.

### Installation

To get started with the `browser-use` integration in AG2, follow these
steps:

1.  Install AG2 with the `browser-use` extra:

    ```bash
    pip install ag2[browser-use]
    ```

    > **Note:** If you have been using `autogen` or `pyautogen`, all you
    > need to do is upgrade it using:
    >
    > ```bash
    > pip install -U autogen[browser-use]
    > ```
    >
    > or
    >
    > ```bash
    > pip install -U pyautogen[browser-use]
    > ```
    >
    > as `pyautogen`, `autogen`, and `ag2` are aliases for the same PyPI
    > package.

2.  Set up Playwright:

    ```bash
    # Installs Playwright and browsers for all OS
    playwright install
    # Additional command, mandatory for Linux only
    playwright install-deps
    ```

3.  For running the code in Jupyter, use `nest_asyncio` to allow nested
    event loops. `bash     pip install nest_asyncio`

You’re all set! Now you can start using browsing features in AG2.

### Imports

```python
import os

import nest_asyncio

from autogen.agentchat import UserProxyAgent
from autogen.agents.experimental import WebSurferAgent

nest_asyncio.apply()
```

### `browser-use` WebSurferAgent

> **Note:** [`Browser Use`](https://github.com/browser-use/browser-use)
> supports the following models: [Supported
> Models](https://docs.browser-use.com/customize/supported-models#supported-models)
>
> We had great experience with `OpenAI`, `Anthropic`, and `Gemini`.
> However, `DeepSeek` and `Ollama` haven’t performed as well.

```python
config_list = [{"model": "gpt-4o-mini", "api_key": os.environ["OPENAI_API_KEY"]}]

llm_config = {
    "config_list": config_list,
}
```

There are two ways to start a chat session which is using only one agent
with LLM configuration.

#### **Recommended:** Using the `run` Method

The new `run` method simplifies the process by eliminating the need for
manual `UserProxyAgent` creation.

-   ✅ **Easier setup** – No need to manually register tools

```python
# The `web_tool="browser_use"` tells the agent to use the `BrowserUseTool` to surf the web.
websurfer = WebSurferAgent(name="WebSurfer", llm_config=llm_config, web_tool="browser_use")

websurfer.run(
    message="Get info from https://docs.ag2.ai/docs/Home",
    tools=websurfer.tools,
    max_turns=2,
    user_input=False,
)
```

#### **Manual Setup:** Using `initiate_chat` Method

This method requires manually creating a `UserProxyAgent` and
registering tools for execution.

-   ⚠️ **More setup required**
-   ⚠️ **Must manually register tools**

```python
websurfer = WebSurferAgent(name="WebSurfer", llm_config=llm_config, web_tool="browser_use")
user_proxy = UserProxyAgent(name="user_proxy", human_input_mode="NEVER")
# WebSurferAgent has a list of tools which are registered for LLM
# We need to register the tools for execution with the UserProxyAgent
for tool in websurfer.tools:
    tool.register_for_execution(user_proxy)

user_proxy.initiate_chat(
    recipient=websurfer,
    message="Get info from https://docs.ag2.ai/docs/Home",
    max_turns=2,
)
```

## WebSurferAgent with `crawl4ai` tool

### Installation

To get started with the `crawl4ai` integration in AG2, follow these
steps:

1.  Install AG2 with the `crawl4ai` extra:

    ```bash
    pip install ag2[crawl4ai]
    ```

    > **Note:** If you have been using `autogen` or `pyautogen`, all you
    > need to do is upgrade it using:
    >
    > ```bash
    > pip install -U autogen[crawl4ai]
    > ```
    >
    > or
    >
    > ```bash
    > pip install -U pyautogen[crawl4ai]
    > ```
    >
    > as `pyautogen`, `autogen`, and `ag2` are aliases for the same PyPI
    > package.

2.  Set up Playwright:

    ```bash
    # Installs Playwright and browsers for all OS
    playwright install
    # Additional command, mandatory for Linux only
    playwright install-deps
    ```

3.  For running the code in Jupyter, use `nest_asyncio` to allow nested
    event loops. `bash     pip install nest_asyncio`

You’re all set! Now you can start using browsing features in AG2.

### Imports

```python
import os

import nest_asyncio

from autogen.agentchat import UserProxyAgent
from autogen.agents.experimental import WebSurferAgent

nest_asyncio.apply()
```

### Crawl4AI WebSurferAgent

> **Note:** [`Crawl4AI`](https://github.com/unclecode/crawl4ai) is built
> on top of [LiteLLM](https://github.com/BerriAI/litellm) and supports
> the same models as LiteLLM.
>
> We had great experience with `OpenAI`, `Anthropic`, `Gemini` and
> `Ollama`. However, as of this writing, `DeepSeek` is encountering some
> issues.

```python
config_list = [{"model": "gpt-4o-mini", "api_key": os.environ["OPENAI_API_KEY"]}]

llm_config = {
    "config_list": config_list,
}
```

There are two ways to start a chat session which is using only one agent
with LLM configuration.

#### **Recommended:** Using the `run` Method

The new `run` method simplifies the process by eliminating the need for
manual `UserProxyAgent` creation.

-   ✅ **Easier setup** – No need to manually register tools

```python
# `web_tool` parameter must be set to `crawl4ai` in order for the `Crawl4AITool` to be used.
websurfer = WebSurferAgent(name="WebSurfer", llm_config=llm_config, web_tool="crawl4ai")

websurfer.run(
    message="Get info from https://docs.ag2.ai/docs/Home",
    tools=websurfer.tools,
    max_turns=2,
    user_input=False,
)
```

#### **Manual Setup:** Using `initiate_chat` Method

This method requires manually creating a `UserProxyAgent` and
registering tools for execution.

-   ⚠️ **More setup required**
-   ⚠️ **Must manually register tools**

```python
user_proxy = UserProxyAgent(name="user_proxy", human_input_mode="NEVER")
websurfer = WebSurferAgent(name="WebSurfer", llm_config=llm_config, web_tool="crawl4ai")

# WebSurferAgent has a list of tools which are registered for LLM
# We need to register the tools for execution with the UserProxyAgent
for tool in websurfer.tools:
    tool.register_for_execution(user_proxy)

user_proxy.initiate_chat(
    recipient=websurfer,
    message="Get info from https://docs.ag2.ai/docs/Home",
    max_turns=2,
)
```

<div className="edit-url-container">
    <a className="edit-url" href="https://github.com/ag2ai/ag2/edit/main/notebook/agents_websurfer.ipynb" target='_blank'><Icon icon="pen" iconType="solid" size="13px"/> Edit this page</a>
</div>
