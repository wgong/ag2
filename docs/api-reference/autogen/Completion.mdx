---
sidebarTitle: Completion
title: autogen.Completion
---
<h2 id="autogen.Completion" class="doc doc-heading">
    <code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>
    <span class="doc doc-object-name doc-class-name">Completion</span>
</h2>

```python
Completion()
```

    `(openai<1)` A class for OpenAI completion API.<br/>It also supports: ChatCompletion, Azure OpenAI API.

### Class Attributes

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### cache_path
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### cache_seed
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### chat_models
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### default_search_space
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### logged_history
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### max_retry_period
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### openai_completion_class
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### optimization_budget
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### price1K
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### request_timeout
<br />

    <br />

<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>
#### retry_wait_time
<br />

    <br />

### Static Methods

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### clear_cache

```python
clear_cache(seed: int | None = None, cache_path_root: str | None = '.cache') -> 
```

    Clear cache.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `seed` | The integer identifier for the pseudo seed.<br/><br/>If omitted, all caches under cache_path_root will be cleared.<br/><br/>**Type:** int \| None<br/><br/>**Default:** None |
| `cache_path_root` | **Type:** str \| None<br/><br/>**Default:** '.cache' |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### cost

```python
cost(response: dict) -> 
```

    Compute the cost of an API call.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `response` | The response from OpenAI API.<br/><br/>**Type:** dict |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### create

```python
create(
    context: dict[str, Any] | None = None,
    use_cache: bool | None = True,
    config_list: list[dict[str, Any]] | None = None,
    filter_func: Callable[[dict[str, Any], dict[str, Any]], bool] | None = None,
    raise_on_ratelimit_or_timeout: bool | None = True,
    allow_format_str_template: bool | None = False,
    **config
) -> 
```

    Make a completion for a given context.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `context` | The context to instantiate the prompt.<br/><br/>It needs to contain keys that are used by the prompt template or the filter function.<br/><br/>E.g., `prompt="Complete the following sentence: \{prefix}, context=\{"prefix": "Today I feel"}`.<br/><br/>The actual prompt will be: "Complete the following sentence: Today I feel".<br/><br/>**Type:** dict[str, typing.Any] \| None<br/><br/>**Default:** None |
| `use_cache` | Whether to use cached responses.<br/><br/>**Type:** bool \| None<br/><br/>**Default:** True |
| `config_list` | List of configurations for the completion to try.<br/><br/>The first one that does not raise an error will be used.<br/><br/>Only the differences from the default config need to be provided.<br/><br/>E.g., ```response = oai.Completion.create( config_list = [ \{ "model": "gpt-4", "api_key": os.environ.get("AZURE_OPENAI_API_KEY"), "api_type": "azure", "base_url": os.environ.get("AZURE_OPENAI_API_BASE"), "api_version": "2024-02-01", }, \{ "model": "gpt-3.5-turbo", "api_key": os.environ.get("OPENAI_API_KEY"), "base_url": "https://api.openai.com/v1", }, \{ "model": "llama-7B", "base_url": "http://127.0.0.1:8080", }, ], prompt="Hi", ) ```<br/><br/>**Type:** list[dict[str, typing.Any]] \| None<br/><br/>**Default:** None |
| `filter_func` | A function that takes in the context and the response and returns a boolean to indicate whether the response is valid.<br/><br/>E.g., ```def yes_or_no_filter(context, config, response): return context.get("yes_or_no_choice", False) is False or any( text in ["Yes.", "No."] for text in oai.Completion.extract_text(response) ) ```<br/><br/>**Type:** Callable[[dict[str, Any], dict[str, Any]], bool] \| None<br/><br/>**Default:** None |
| `raise_on_ratelimit_or_timeout` | Whether to raise RateLimitError or Timeout when all configs fail.<br/><br/>When set to False, -1 will be returned when all configs fail.<br/><br/>**Type:** bool \| None<br/><br/>**Default:** True |
| `allow_format_str_template` | Whether to allow format string template in the config.<br/><br/>**Type:** bool \| None<br/><br/>**Default:** False |
| `**config` | Configuration for the openai API call.<br/><br/>This is used as parameters for calling openai API.<br/><br/>The "prompt" or "messages" parameter can contain a template (str or Callable) which will be instantiated with the context.<br/><br/>Besides the parameters for the openai API call, it can also contain: - `max_retry_period` (int): the total time (in seconds) allowed for retrying failed requests.<br/><br/>- `retry_wait_time` (int): the time interval to wait (in seconds) before retrying a failed request.<br/><br/>- `cache_seed` (int) for the cache.<br/><br/>This is useful when implementing "controlled randomness" for the completion.<br/><br/> |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### extract_text

```python
extract_text(response: dict) -> list[str]
```

    Extract the text from a completion or chat response.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `response` | The response from OpenAI API.<br/><br/>**Type:** dict |

<b>Returns:</b>
| Type | Description |
|--|--|
| list[str] | A list of text in the responses. |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### extract_text_or_function_call

```python
extract_text_or_function_call(response: dict) -> list[str]
```

    Extract the text or function calls from a completion or chat response.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `response` | The response from OpenAI API.<br/><br/>**Type:** dict |

<b>Returns:</b>
| Type | Description |
|--|--|
| list[str] | A list of text or function calls in the responses. |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### instantiate

```python
instantiate(
    template: str | None,
    context: dict[str, Any] | None = None,
    allow_format_str_template: bool | None = False
) -> 
```

    

<b>Parameters:</b>
| Name | Description |
|--|--|
| `template` | **Type:** str \| None |
| `context` | **Type:** dict[str, typing.Any] \| None<br/><br/>**Default:** None |
| `allow_format_str_template` | **Type:** bool \| None<br/><br/>**Default:** False |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### print_usage_summary

```python
print_usage_summary() -> dict
```

    Return the usage summary.

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### set_cache

```python
set_cache(seed: int | None = 41, cache_path_root: str | None = '.cache') -> 
```

    Set cache path.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `seed` | The integer identifier for the pseudo seed.<br/><br/>Results corresponding to different seeds will be cached in different places.<br/><br/>**Type:** int \| None<br/><br/>**Default:** 41 |
| `cache_path_root` | **Type:** str \| None<br/><br/>**Default:** '.cache' |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### start_logging

```python
start_logging(
    history_dict: dict[str, Any] | None = None,
    compact: bool | None = True,
    reset_counter: bool | None = True
) -> 
```

    Start book keeping.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `history_dict` | A dictionary for book keeping.<br/><br/>If no provided, a new one will be created.<br/><br/>**Type:** dict[str, typing.Any] \| None<br/><br/>**Default:** None |
| `compact` | Whether to keep the history dictionary compact.<br/><br/>Compact history contains one key per conversation, and the value is a dictionary like:<br/><br/>**Type:** bool \| None<br/><br/>**Default:** True |
| `reset_counter` | whether to reset the counter of the number of API calls.<br/><br/>**Type:** bool \| None<br/><br/>**Default:** True |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### stop_logging

```python
stop_logging() -> 
```

    End book keeping.

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### test

```python
test(
    cls,
    data,
    eval_func=None,
    use_cache=True,
    agg_method='avg',
    return_responses_and_per_instance_result=False,
    logging_level=30,
    **config
) -> 
```

    Evaluate the responses created with the config for the OpenAI API call.<br/>

<b>Parameters:</b>
| Name | Description |
|--|--|
| `cls` |  |
| `data` | The list of test data points.<br/><br/> |
| `eval_func=None` |  |
| `use_cache=True` |  |
| `agg_method='avg'` |  |
| `return_responses_and_per_instance_result=False` |  |
| `logging_level=30` |  |
| `**config` |  |

<br />

<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>
#### tune

```python
tune(
    cls,
    data: list[dict[str, Any]],
    metric: str,
    mode: str,
    eval_func: Callable,
    log_file_name: str | None = None,
    inference_budget: float | None = None,
    optimization_budget: float | None = None,
    num_samples: int | None = 1,
    logging_level: int | None = 30,
    **config
) -> 
```

    Tune the parameters for the OpenAI API call.<br/>TODO: support parallel tuning with ray or spark.<br/>TODO: support agg_method as in test

<b>Parameters:</b>
| Name | Description |
|--|--|
| `cls` |  |
| `data` | The list of data points.<br/><br/>**Type:** list[dict[str, typing.Any]] |
| `metric` | The metric to optimize.<br/><br/>**Type:** str |
| `mode` | The optimization mode, "min" or "max.<br/><br/>**Type:** str |
| `eval_func` | The evaluation function for responses.<br/><br/>The function should take a list of responses and a data point as input, and return a dict of metrics.<br/><br/>For example,<br/><br/>**Type:** Callable |
| `log_file_name` | **Type:** str \| None<br/><br/>**Default:** None |
| `inference_budget` | **Type:** float \| None<br/><br/>**Default:** None |
| `optimization_budget` | **Type:** float \| None<br/><br/>**Default:** None |
| `num_samples` | **Type:** int \| None<br/><br/>**Default:** 1 |
| `logging_level` | **Type:** int \| None<br/><br/>**Default:** 30 |
| `**config` |  |

<br />