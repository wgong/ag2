---
title: LiteLLM with Azure
sidebarTitle: LiteLLM with Azure
---

Before starting this guide, ensure you have completed the [Installation Guide](/docs/user-guide/models/litellm-proxy-server/installation) and installed all required dependencies.

## Run LiteLLM as a Docker Container

To connect LiteLLM with an `Azure model`, configure your `litellm_config.yaml` as follows:

```yaml
model_list:
  - model_name: azure-gpt-4o-mini
    litellm_params:
      model: azure/gpt-4o-mini
      api_base: os.environ/AZURE_API_BASE
      api_key: os.environ/AZURE_API_KEY
      api_version: os.environ/AZURE_API_VERSION
```

Before starting the container, ensure you have correctly set the following environment variables:
    - `AZURE_API_KEY`
    - `AZURE_API_BASE`
    - `AZURE_API_VERSION`

Run the container using:
```bash
docker run -v $(pwd)/litellm_config.yaml:/app/config.yaml  \
-e AZURE_API_KEY="your_api_key" -e AZURE_API_BASE="your_api_base_url" -e AZURE_API_VERSION="your_api_version"\
-p 4000:4000 ghcr.io/berriai/litellm:main-latest --config /app/config.yaml --detailed_debug
```

Once running, LiteLLM will be accessible at: `http://0.0.0.0:4000`


To confirm that `config.yaml` is correctly mounted, check the logs:

```console
...
13:49:43 - LiteLLM Proxy:DEBUG: proxy_server.py:1507 - loaded config={
    "model_list": [
        {
            "model_name": "azure-gpt-4o-mini",
            "litellm_params": {
                "model": "azure/gpt-4o-mini",
                "api_base": "os.environ/AZURE_API_BASE",
                "api_key": "os.environ/AZURE_API_KEY",
                "api_version": "os.environ/AZURE_API_VERSION"
            }
        }
    ]
}
...
```

## Initiate Chat
To communicate with LiteLLM, configure the model in `config_list` and initiate a chat session.

```python
from autogen import AssistantAgent, UserProxyAgent

config_list = [
    {
        "model": "azure-gpt-4o-mini",
        "base_url": "http://0.0.0.0:4000",
    }
]

user_proxy = UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
)
assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config_list},
)


user_proxy.initiate_chat(
    recipient=assistant,
    message="Solve the following equation: 2x + 3 = 7",
    max_turns=3,
)
```

<div className="edit-url-container">
    <a className="edit-url" href="https://github.com/ag2ai/ag2/edit/main/website/docs/user-guide/models/litellm-proxy-server/azure.mdx" target='_blank'><Icon icon="pen" iconType="solid" size="13px"/> Edit this page</a>
</div>
